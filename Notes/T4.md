# Tutorial 4

## __data_ingestion.py__

- this is the script which imports the data from cloud or local.
- Will also import the custom exception and logging we created earlier from src folder.
- Will also import dataclasses
- Whenever we use this data ingestion components, there will be some inputs which will be required by the data ingestion components. Eg- training data path, test data path, save location, etc. These kinds of inputs will be created in another class known as data ingestion class - `DataIngestionConfig`.

- Reason why we are making `DataIngestionConfig` because in the data ingestion components any input which is required will be given by through this `DataIngestionConfig`.

- Using dataclass: Usually inside a class we used `__init__` to define a variable. If you use __dataclass__ you will be able to directly define your class variables.

### dataclass
The `@dataclass` decorator in Python is used to automatically generate special methods like `__init__`, `__repr__`, `__eq__`, and others for user-defined classes. It is part of the `dataclasses` module, introduced in Python 3.7.

```
from dataclasses import dataclass

@dataclass
class Point:
    x: int
    y: int
```

This is equivalent to writing:

```
class Point:
    def __init__(self, x: int, y: int):
        self.x = x
        self.y = y

    def __repr__(self):
        return f"Point(x={self.x}, y={self.y})"

    def __eq__(self, other):
        return isinstance(other, Point) and self.x == other.x and self.y == other.y
```

#### Key Features

- Automatic `__init__` method: You donâ€™t need to write boilerplate initialization code.
- Optional immutability with `frozen=True`.
- Default values and `field()` customization.
- Type hints are required for each field.

#### Additional Options

```
from dataclasses import dataclass, field

@dataclass(order=True, frozen=True)
class Item:
    name: str
    price: float = field(default=0.0, compare=False)
```

- `order=True`: adds comparison methods like `__lt__`, `__le__`, etc.
- `frozen=True`: makes instances immutable (like namedtuples).
- `field()`: used for fine-grained control (e.g., default values, exclusion from comparison or repr, etc.).

Now back to the __data ingestion component__.

```
from dataclasses import dataclass

@dataclass
class DataIngestionConfig:
    """
    Data Ingestion Configuration Class
    """
    ### Paths for the dataset and train/test splits
    ### raw_data_path,train_data_path and test_data_path are defined as strings
    ### All the outputs of data ingestion will be stored in the 'artifacts' directory
    train_data_path: str = os.path.join('artifacts', 'train.csv')
    test_data_path: str = os.path.join('artifacts', 'test.csv')
    raw_data_path: str = os.path.join('artifacts', 'data.csv')
```

Now because of the above code the data ingestion component knows where to save the train data and test data. 

Now if you are only defining class variables, it would be better if you go ahead with `@dataclass` but if you have functions inside the class then its better to go ahead with the constructor functions `__init__`.


`DataIngestionConfig()` will consist of the three values: `train_data_path`, `test_data_path` and `raw_data_path`. And as soon as the class `DataIngestion` is called this line will get executed - `self.ingestion_config = DataIngestionConfig()` and the above 3 variables will be saved in this `ingestion_config`.

Now we will create our own function: `initiate_data_ingestion()`. This function ingest data from databases or any other location.

Now to add details about the database from which the data is being loaded say MongoDB or GCP BigQuery, you can create the client for it in `utils.py`. 

Now in the function we will put the steps in try and except to make sure that we are able to catch the errors. To get the location of the file __StudentsPerformance.csv__, right click on the file in the VS code directory in the exporer section and 
select __copy relative path__ from the dropdown.

Make sure you keep adding the logs so that you know after which line in the function the exception has happened.

Now in the earlier code we have already defined the path for training data, testing data and raw data. Now __artifacts__ is basically a folder, now lets create this folder.

```
# Create directories if they do not exist
os.makedirs(os.path.dirname(self.ingestion_config.train_data_path), exist_ok=True)
# Save the raw data to a CSV file
df.to_csv(self.ingestion_config.raw_data_path, index=False, header=True)
logging.info("Raw data saved to CSV")
```

`exist_ok = True` if that particular folder is already there it will be there only and will need not be deleted and a new folder will be created. We can also save the raw data in the path.

The function `initiate_data_ingestion` will return 3 paprameters which will be used in the next step which is data transformation.

21:10

